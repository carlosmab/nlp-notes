{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF from Scratch\n",
    "Using bbc_text_cls.csv \n",
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
    "\n",
    "### Hypothesis:\n",
    "- Words that appear often in the documents: Term frequency high (TF)\n",
    "- Relatively unique compared to whole data set: Document Frequency Low: Inverse Document Frequency high (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for nltk tokenizer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dataframe\n",
    "\n",
    "df = pd.read_csv('bbc_text_cls.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate word2idx\n",
    "# convert documents into sequences of ints / ids / indices\n",
    "\n",
    "current_idx = 0\n",
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "\n",
    "for document in df['text']:\n",
    "    words = word_tokenize(document.lower())\n",
    "    doc_as_int = [] # Saving words as the index\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = current_idx\n",
    "            current_idx += 1\n",
    "        \n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse Mapping\n",
    "idx2word = [word for word, idx in word2idx.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents\n",
    "N = len(df['text'])\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34762"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words\n",
    "V = len(word2idx)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create term-frequency matrix\n",
    "# From scratch\n",
    "\n",
    "tf = np.zeros((N, V))\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate term-frequency TF matrix\n",
    "\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i, j] += 1\n",
    "        \n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF\n",
    "document_freq = np.sum(tf > 0, axis=0) # In how many docs a word appears, shape = (V,) \n",
    "idf = np.log(N / document_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute TF-IDF\n",
    "\n",
    "tf_idf = tf * idf # Numpy perform element-wise multiplication with '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  sport\n",
      "Text:  Athens memories soar above lows\n",
      "Top 5 terms: \n",
      "paula\n",
      "athens\n",
      "1500m\n",
      "her\n",
      "kelly\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "\n",
    "i = np.random.choice(N)\n",
    "row = df.iloc[i]\n",
    "\n",
    "print('Label: ', row['labels'])\n",
    "print('Text: ', row['text'].split(\"\\n\", 1)[0])\n",
    "print('Top 5 terms: ')\n",
    "\n",
    "scores = tf_idf[i]\n",
    "indices = (-scores).argsort() # argsort return the indices instead the scores (descending order)\n",
    "\n",
    "for j in indices[:5]:\n",
    "    print(idx2word[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2225x29421 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 449254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise: user CountVectorizer to form the counts instead\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercis: use Scipy's csr_matrix instead"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
