{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
      "From (redirected): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&confirm=t&uuid=09cc189b-0173-404d-bcf7-967829e705a3\n",
      "To: /home/carlosm/Development/python/courses/nlp_udemy/vectorizers/GoogleNews-vectors-negative300.bin.gz\n",
      "100%|██████████████████████████████████████| 1.65G/1.65G [02:47<00:00, 9.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec (Google)\n",
    "# Costly operation to get our own word vectors\n",
    "\n",
    "import gdown\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting word vectors\n",
    "# Using scipy 1.12.0 (problem with newer versions)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\n",
    "    'GoogleNews-vectors-negative300.bin',\n",
    "    binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function find_analogies\n",
    "\n",
    "def find_analogies(w1, w2, w3):\n",
    "    # w1 - w2 = ? - w3\n",
    "    # eg. king - man = ? - woman\n",
    "    #       ? = + king + woman -man\n",
    "    \n",
    "    r = word_vectors.most_similar(positive=[w1, w3], negative=[w2])\n",
    "    print(f\"\"\"{w1}, {w2}, {r[0][0]}, {w3}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king, man, queen, woman\n"
     ]
    }
   ],
   "source": [
    "# Examples:\n",
    "\n",
    "find_analogies(\"king\", \"man\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france, paris, england, london\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'paris', 'london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "einstein, scientist, jude, philosopher\n"
     ]
    }
   ],
   "source": [
    "find_analogies('einstein', 'scientist', 'philosopher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbors\n",
    "\n",
    "def get_nearest_neighbors(w):\n",
    "    r = word_vectors.most_similar(positive=[w])\n",
    "    print(f\"Neighbors of {w}: \")\n",
    "\n",
    "    for word, score in r:\n",
    "        print(f\"Word: {word};  Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of king: \n",
      "Word: kings;  Score: 0.7138045430183411\n",
      "Word: queen;  Score: 0.6510956883430481\n",
      "Word: monarch;  Score: 0.6413194537162781\n",
      "Word: crown_prince;  Score: 0.6204220056533813\n",
      "Word: prince;  Score: 0.6159993410110474\n",
      "Word: sultan;  Score: 0.5864824056625366\n",
      "Word: ruler;  Score: 0.5797567367553711\n",
      "Word: princes;  Score: 0.5646552443504333\n",
      "Word: Prince_Paras;  Score: 0.5432944297790527\n",
      "Word: throne;  Score: 0.5422105193138123\n"
     ]
    }
   ],
   "source": [
    "get_nearest_neighbors('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of february: \n",
      "Word: january;  Score: 0.7155449390411377\n",
      "Word: april;  Score: 0.7115830779075623\n",
      "Word: september;  Score: 0.6933045387268066\n",
      "Word: december;  Score: 0.6915465593338013\n",
      "Word: july;  Score: 0.689647376537323\n",
      "Word: october;  Score: 0.6687516570091248\n",
      "Word: november;  Score: 0.6433451175689697\n",
      "Word: june;  Score: 0.6238243579864502\n",
      "Word: feb;  Score: 0.6054605841636658\n",
      "Word: norway;  Score: 0.5665180087089539\n"
     ]
    }
   ],
   "source": [
    "get_nearest_neighbors('february')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
